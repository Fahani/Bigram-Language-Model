{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP\n",
    "\n",
    "## Problem 1\n",
    "Write a python program to perform the following tasks:\n",
    "\n",
    "1) Estimate a bigram language model on “hw2_training_sets.txt”. Use your language model to compute:\n",
    "\n",
    "    A. the probability,\n",
    "    B. the probability normalized by sentence length,\n",
    "    C. and the perplexity of the 5 sentences given in “test_set.txt”. \n",
    "\n",
    "The training and test files have already been tokenized.\n",
    "\n",
    "2) Explain how you have handled unknown words that appear in the test set.\n",
    "\n",
    "Submission:\n",
    "- Submit your python code as “lastname-firstname-part1.py”.\n",
    "- Submit an output file “output.txt” with each line containing all required values for the respective sentence, separated by comma. Note: This time, you are not allowed to use NLTK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read in lines:\n",
      " ['This is the genealogy of Jesus the Messiah the son of David , the son of Abraham :', 'Thus there were fourteen generations in all from Abraham to David , fourteen from David to the exile to Babylon , and fourteen from the exile to the Messiah .', 'This is how the birth of Jesus the Messiah came about : his mother Mary was pledged to be married to Joseph , but before they came together , she was found to be pregnant through the Holy Spirit .', 'Because Joseph her husband was faithful to the law , and yet did not want to expose her to public disgrace , he had in mind to divorce her quietly .', 'But after he had considered this , an angel of the Lord appeared to him in a dream and said , ‘ Joseph son of David , do not be afraid to take Mary home as your wife , because what is conceived in her is from the Holy Spirit .']\n",
      "\n",
      "Words in training_set: 215745 + vocabulary size: 7146 = 215746 tokens in dict1\n",
      "Number of <s>: 7728\n",
      "Number of </s>: 7728\n",
      "\n",
      "listWords:\n",
      " ['<s>', 'This', 'is', 'the', 'genealogy', 'of', 'Jesus', 'the', 'Messiah', 'the', 'son', 'of', 'David', ',', 'the', 'son', 'of', 'Abraham', ':', '</s>', '<s>', 'Thus', 'there', 'were', 'fourteen', 'generations', 'in', 'all', 'from', 'Abraham', 'to', 'David', ',', 'fourteen', 'from', 'David', 'to', 'the', 'exile', 'to', 'Babylon', ',', 'and', 'fourteen', 'from', 'the', 'exile', 'to', 'the', 'Messiah', '.', '</s>', '<s>', 'This', 'is']\n"
     ]
    }
   ],
   "source": [
    "# Read in training set\n",
    "lines = []\n",
    "for line in open('training_set.txt'):\n",
    "    if line.strip():\n",
    "        lines.append(line.strip())\n",
    "print('Read in lines:\\n' , lines[0:5])\n",
    "\n",
    "dict1 = {'<s>': 0, '</s>': 0, '<UNK>': 1} #Make sure '<UNK>' is part of dictionary for later\n",
    "#punctuation = '\\“\\”\\\"\\‘\\'\\''\n",
    "\n",
    "listWords = [] #This will be the whole document word by word\n",
    "\n",
    "for line in lines:\n",
    "    dict1['<s>'] += 1\n",
    "    listWords.append('<s>') #Append <s> and </s> to every line\n",
    "    dict1['</s>'] += 1\n",
    "    for word in line.split():       \n",
    "        listWords.append(word)\n",
    "        \n",
    "        if word not in dict1:\n",
    "            dict1[word] = 1\n",
    "        else:\n",
    "            dict1[word] += 1\n",
    "    listWords.append('</s>')\n",
    "    \n",
    "#\n",
    "#\n",
    "#\n",
    "#Substitute low-frequency words with '<UNK>' and keep count of them\n",
    "'''\n",
    "keysToDelete = []\n",
    "for key in dict1:\n",
    "    if dict1[key] == 1:\n",
    "        keysToDelete.append(dict1[key])\n",
    "        wordIndex = listWords.index(key)\n",
    "        listWords[wordIndex] = '<UNK>'\n",
    "        dict1['<UNK>'] += 1\n",
    "\n",
    "for word in keysToDelete:\n",
    "    del dict1['key']\n",
    "'''  \n",
    "\n",
    "'''\n",
    "#Should I delete punctuation?\n",
    "for char in punctuation:\n",
    "    if char in dict1:\n",
    "        del dict1[char]\n",
    "for char in punctuation:\n",
    "    if char in listWords:\n",
    "        listWords.remove(char)\n",
    "'''\n",
    "#\n",
    "# NO SMOOTHING FOR UNIGRAMS!!! ONLY BIGRAMS \n",
    "#\n",
    "\n",
    "vocabulary = set(dict1)\n",
    "#print('Vocabulary size:', len(vocabulary))\n",
    "\n",
    "countTokens = sum(dict1.values())\n",
    "print('\\nWords in training_set:', len(listWords),'+ vocabulary size:', len(vocabulary),'=', countTokens, 'tokens in dict1')\n",
    "\n",
    "print('Number of <s>:', dict1['<s>'])\n",
    "print('Number of </s>:', dict1['</s>'])\n",
    "\n",
    "#print('Count words in whole document:', len(listWords))\n",
    "print('\\nlistWords:\\n', listWords[0:55])\n",
    "\n",
    "#print('<s>' in vocabulary)\n",
    "#print('\\‘' in vocabulary)\n",
    "#print('<UNK>' in listWords)\n",
    "#print('' in dict1)\n",
    "#print('' in vocabulary)\n",
    "#print('' in listWords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigram Dict\n",
    "\n",
    "A bigram language model requires bigram probabilities, which are calculated by taking the counts of word co-occurences and dividing them by the count of the current word. These values are then presented in a word-to-word matrix.\n",
    "\n",
    "P(Wn, Wn-1) / P(Wn)\n",
    "\n",
    "To get the bigram counts, I have to keep track of the previous word and the current word.\n",
    "\n",
    "I could use an array, but I think a dictionary would make it easier\n",
    "'''\n",
    "rows = []\n",
    "for i in range(len(vocabulary)):\n",
    "    column = [0] * len(vocabulary)\n",
    "    rows.append(column)\n",
    "    \n",
    "#print(rows[0][0:5])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab: ['heart’s', 'Continue', 'shield', 'grabbed', '“', 'restless', 'wrongdoers', 'driving', 'acceptably', 'plague']\n",
      "Size bigramDict: 56916\n"
     ]
    }
   ],
   "source": [
    "# Initialize word-to-word co-occurence matrix using vocabulary list\n",
    "# USE DICT OF DICTS TO CREATE BIGRAM MATRIX\n",
    "\n",
    "listVocab = list(vocabulary) #convert set to list\n",
    "print('Vocab:', listVocab[0:10])\n",
    "\n",
    "# Create dict with all bigrams from the training_set and their counts + one key for unknown bigrams in the test set\n",
    "bigramDict = {'<UNK> <UNK>':0}\n",
    "for word1, word2 in zip(listWords,listWords[1:]): #the whole document with the words in order\n",
    "    bigram1 = word1 + ' ' + word2\n",
    "    if bigram1 not in bigramDict:\n",
    "        bigramDict[bigram1] = 1\n",
    "    else:\n",
    "        bigramDict[bigram1] += 1\n",
    "\n",
    "# Add +1 Smoothing\n",
    "for key in bigramDict:\n",
    "    bigramDict[key] += 1\n",
    "\n",
    "print('Size bigramDict:', len(bigramDict)) #56916\n",
    "#print(bigramDict)\n",
    "#print('<s> is' in bigramDict)\n",
    "#print('<s> Love' in bigramDict)\n",
    "#print('<s> love' in bigramDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size bigramProbs: 56916\n"
     ]
    }
   ],
   "source": [
    "# To get the bigram probability, I have to take the bigram counts and divide them by the unigram counts\n",
    "# P(word2 | word1) = bigramDict['word1 word2'] / unigramDict['word1'] + len(vocabulary)\n",
    "\n",
    "bigramProbs = {}\n",
    "for key in bigramDict:\n",
    "    word1, word2 = key.split()\n",
    "    probability = bigramDict[key] / (dict1[word1] + len(vocabulary))\n",
    "    bigramProbs[key] = probability\n",
    "        \n",
    "print('Size bigramProbs:', len(bigramProbs))\n",
    "#print(bigramProbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line 1 \n",
      " When trouble or persecution comes because of the word , they quickly fall away . \n",
      "\n",
      "Bigrams:\n",
      " ['<s> When', 'When trouble', 'trouble or', 'or persecution', 'persecution comes', 'comes because', 'because of', 'of the', 'the word', 'word ,', ', they', 'they quickly', 'quickly fall', 'fall away', 'away .', '. </s>'] \n",
      "\n",
      "Product: 3.88993088935546e-41 \n",
      "\n",
      "Line 2 \n",
      " The people were amazed when they saw the mute speaking , the crippled made well , the lame walking and the blind seeing . \n",
      "\n",
      "Bigrams:\n",
      " ['<s> The', 'The people', 'people were', 'were amazed', 'amazed when', 'when they', 'they saw', 'saw the', 'the mute', 'mute speaking', 'speaking ,', ', the', 'the crippled', 'crippled made', 'made well', 'well ,', ', the', 'the lame', 'lame walking', 'walking and', 'and the', 'the blind', 'blind seeing', 'seeing .', '. </s>'] \n",
      "\n",
      "Product: 2.5303743634734513e-69 \n",
      "\n",
      "Line 3 \n",
      " When Pilate saw that he was getting nowhere , but that instead an uproar was starting , he took water and washed his hands in front of the crowd . \n",
      "\n",
      "Bigrams:\n",
      " ['<s> When', 'When Pilate', 'Pilate saw', 'saw that', 'that he', 'he was', 'was getting', 'getting nowhere', 'nowhere ,', ', but', 'but that', 'that instead', 'instead an', 'an uproar', 'uproar was', 'was starting', 'starting ,', ', he', 'he took', 'took water', 'water and', 'and washed', 'washed his', 'his hands', 'hands in', 'in front', 'front of', 'of the', 'the crowd', 'crowd .', '. </s>'] \n",
      "\n",
      "Product: 9.75661631956433e-87 \n",
      "\n",
      "Line 4 \n",
      " As they were coming down the mountain , lord gave them orders not to tell anyone what they had seen until the son of Man had risen from the dead . \n",
      "\n",
      "Bigrams:\n",
      " ['<s> As', 'As they', 'they were', 'were coming', 'coming down', 'down the', 'the mountain', 'mountain ,', ', lord', 'lord gave', 'gave them', 'them orders', 'orders not', 'not to', 'to tell', 'tell anyone', 'anyone what', 'what they', 'they had', 'had seen', 'seen until', 'until the', 'the son', 'son of', 'of Man', 'Man had', 'had risen', 'risen from', 'from the', 'the dead', 'dead .', '. </s>'] \n",
      "\n",
      "Product: 1.3783365111189162e-86 \n",
      "\n",
      "Line 5 \n",
      " A certain man from Cyrene , Simon , the father of Alexander and Rufus , was passing by on his way in from the country . \n",
      "\n",
      "Bigrams:\n",
      " ['<s> A', 'A certain', 'certain man', 'man from', 'from Cyrene', 'Cyrene ,', ', Simon', 'Simon ,', ', the', 'the father', 'father of', 'of Alexander', 'Alexander and', 'and Rufus', 'Rufus ,', ', was', 'was passing', 'passing by', 'by on', 'on his', 'his way', 'way in', 'in from', 'from the', 'the country', 'country .', '. </s>'] \n",
      "\n",
      "Product: 1.1497889444023886e-78 \n",
      "\n",
      "Probabilties test_set.txt: [3.88993088935546e-41, 2.5303743634734513e-69, 9.75661631956433e-87, 1.3783365111189162e-86, 1.1497889444023886e-78]\n",
      "Sentence lengths: [17, 26, 32, 33, 28]\n"
     ]
    }
   ],
   "source": [
    "# A. The probability of each sentence in the test set\n",
    "# P(a,b,c,d) = P(a)•P(b|a)•P(c|ab)•P(d|abc)\n",
    "# with Markov assumption aka, independence: P(a,b,c,d) = P(a)•P(b|a)•P(c|b)•P(d|c)\n",
    "# i don't need P(a) because it's always 1\n",
    "\n",
    "#Read in test set\n",
    "linesT = [line.strip() for line in open('test_set.txt')]\n",
    "#print(linesT, '\\n')\n",
    "\n",
    "vocabularySize = len(dict1)\n",
    "\n",
    "pTestSet = []\n",
    "sentenceLengths = []\n",
    "\n",
    "for line in linesT:\n",
    "    print('Line',linesT.index(line) + 1,'\\n', line, '\\n')\n",
    "    words = line.split()\n",
    "    words.insert(0, '<s>') #Add <s> and </s> to each line\n",
    "    words.append('</s>')\n",
    "    \n",
    "    sentenceLengths.append(len(words))\n",
    "    \n",
    "    testBigrams = []\n",
    "    for word1, word2 in zip(words,words[1:]): #the whole test document with the words in order\n",
    "        bigram1 = word1 + ' ' + word2\n",
    "        testBigrams.append(bigram1)\n",
    "    print('Bigrams:\\n', testBigrams, '\\n')\n",
    "    product = 1\n",
    "    for i in range(len(testBigrams)):\n",
    "        # I don't need this because all of my sentences start with '<s>'\n",
    "        '''\n",
    "        if i == 0: # just P(w1), this is '<s>' for every sentence, but this allows my program to work in any case\n",
    "            if words[0] not in dict1: # first word is unknown \n",
    "                firstWord = '<UNK>'\n",
    "            else:\n",
    "                firstWord = words[0]\n",
    "        '''\n",
    "            \n",
    "        firstWordProbability = 1\n",
    "            #print('P(',firstWord,')=', round(firstWordProbability, 4))\n",
    "        \n",
    "        # for the rest of the words\n",
    "        currentBigram = testBigrams[i]\n",
    "                  \n",
    "        if currentBigram not in bigramProbs:\n",
    "            currentBigram = '<UNK> <UNK>'\n",
    "        \n",
    "        #print('Bigram:', currentBigram, 'Prob:', bigramProbs[currentBigram] )\n",
    "        # Incorporate probability into product  \n",
    "        product = product * bigramProbs[currentBigram] \n",
    "        \n",
    "    print('Product:', product, '\\n')\n",
    "    pTestSet.append(product)\n",
    "\n",
    "print('Probabilties test_set.txt:', pTestSet)\n",
    "print('Sentence lengths:', sentenceLengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P normalized by sentence length: [0.004196988294634119, 0.0022996458186199404, 0.0020519444566270088, 0.0025012798276624324, 0.0016460788978307649]\n"
     ]
    }
   ],
   "source": [
    "# B. The probability normalized by sentence length.\n",
    "# Divide the probability of the whole sentence by the number of tokens in the sentence.\n",
    "# Take the log of that number\n",
    "# Take the exp of that number\n",
    "\n",
    "import math \n",
    "\n",
    "#(math.log(14))\n",
    "\n",
    "normalizedBySentenceLength = []\n",
    "\n",
    "for i in range(len(pTestSet)):\n",
    "    normalizedProb1 = math.exp(math.log(pTestSet[i]) / sentenceLengths[i])\n",
    "    normalizedBySentenceLength.append(normalizedProb1)\n",
    "    \n",
    "print('P normalized by sentence length:', normalizedBySentenceLength)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: [238.26609220676352, 434.8495720093622, 487.3426260493438, 399.795332349739, 607.5042947928068]\n"
     ]
    }
   ],
   "source": [
    "# C. The perplexity of the 5 sentences given in “test_set.txt”\n",
    "# To calculate Perplexity, calculate the probability of the sentences. If the probability is high, the perplexity is low.\n",
    "\n",
    "# Perplexity = the nth root of (1 / p(w1,w2,...wn) )\n",
    "# multiply all the probabilities of the words from the sentence together.\n",
    "# divide that number by one.\n",
    "# take the nth root of that number. (n is the number of words in the sentence)\n",
    "\n",
    "# import math\n",
    "\n",
    "PP = []\n",
    "\n",
    "for i in range(len(pTestSet)):\n",
    "    perplexity = (1 / pTestSet[i]) ** (1/sentenceLengths[i])\n",
    "    PP.append(perplexity)\n",
    "    \n",
    "print('Perplexity:', PP)\n",
    "\n",
    "# Create output file\n",
    "outputFile = open('output.txt','w') \n",
    "\n",
    "for i in range(len(pTestSet)):\n",
    "    # 1)probability of sentence , 2) probability of sentence normalized by sentence length , 3) perplexity\n",
    "    string1 = str(pTestSet[i]) + ',' + str(normalizedBySentenceLength[i]) + ',' + str(PP[i]) + '\\n'\n",
    "    outputFile.write(string1)\n",
    " \n",
    "outputFile.close() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Explain how you have handled unknown words that appeared in the test set.\n",
    "\n",
    "When I initialized my unigram and bigram dictionaries, I added a key called '<UNK>' in the unigram dictionary and '<UNK> <UNK>' in the bigram dictionary. When I come across a word in the test set that's not in the bigram dictionary, I use the bigram['<UNK> <UNK>'] / unigram['<UNK>'] probability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "Sample a sentence from your language model and compute its perplexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> regarding the street , temperate , pay , gnashes his commands will greatly in paradise .\n"
     ]
    }
   ],
   "source": [
    "# To sample a sentence, I start with '<s>' and set what possible words can come next. I stop when the chosen word is </s>.\n",
    "# I use numpy.random.choice() to choose a possible next word.\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "mySentence = '<s>'\n",
    "currentWord = '<s>' #start at the beginning of the sentence\n",
    "\n",
    "while currentWord != '</s>' and currentWord != '.' and currentWord != '?': \n",
    "#while currentWord != '</s>': \n",
    "    possibleNext = []\n",
    "    for key in bigramDict:\n",
    "        w1, w2 = key.split()\n",
    "        if w1 == currentWord:\n",
    "            possibleNext.append(w2)\n",
    "    #print(len(possibleNext))\n",
    "\n",
    "    array1 = np.array(possibleNext) #make an array of all the possibilities\n",
    "    nextWord = np.random.choice(a = array1) #randomly select one of the possible words\n",
    "    #print(nextWord)\n",
    "    mySentence = mySentence + ' ' + nextWord\n",
    "    currentWord = nextWord\n",
    "    \n",
    "print(mySentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability: 1.4108363150719034e-58\n",
      "Perplexity: 2529.134716046838\n"
     ]
    }
   ],
   "source": [
    "# Compute the perplexity of the sampled sentence.\n",
    "# Perplexity = the nth root of (1 / p(w1,w2,...wn) )\n",
    "# multiply all the probabilities of the words from the sentence together.\n",
    "# divide that number by one.\n",
    "# take the nth root of that number. (n is the number of words in the sentence)\n",
    "\n",
    "allWords = mySentence.split()\n",
    "sentenceBigrams = []\n",
    "for word1, word2 in zip(allWords,allWords[1:]):\n",
    "    bigram1 = word1 + ' ' + word2\n",
    "    sentenceBigrams.append(bigram1)\n",
    "#print(sentenceBigrams)\n",
    "\n",
    "probabilityWords = 1\n",
    "        \n",
    "for i in range(len(sentenceBigrams)):\n",
    "    currentBigram = sentenceBigrams[i]\n",
    "    w1, w2 = currentBigram.split()\n",
    "    \n",
    "    if currentBigram not in bigramDict:\n",
    "        currentBigram = '<UNK> <UNK>'\n",
    "\n",
    "    probabilityWords = probabilityWords * bigramProbs[currentBigram]\n",
    "    \n",
    "perplexity1 = (1 / probabilityWords) ** (1/len(allWords))\n",
    "\n",
    "print('Probability:', probabilityWords)\n",
    "print('Perplexity:', perplexity1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
